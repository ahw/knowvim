// Generated by CoffeeScript 1.8.0
(function() {
  window.WordTokenizer = (function() {
    var LOG, getSmallWordTokenType;

    LOG = new Logger({
      module: 'tokenizer',
      prefix: 'WORD TOKENIZER'
    });

    getSmallWordTokenType = function(ch) {
      var regexps, types;
      regexps = Helpers.smallWordTokenRegexps;
      types = Helpers.smallWordTokenTypes;
      if (regexps.SPECIAL.test(ch)) {
        return types.SPECIAL;
      } else if (regexps.ALPHA_NUM.test(ch)) {
        return types.ALPHA_NUM;
      } else if (regexps.EMPTY_LINE.test(ch)) {
        return types.EMPTY_LINE;
      } else if (regexps.WHITESPACE.test(ch)) {
        return types.WHITESPACE;
      } else {
        return LOG.warn('Unknown character type for "' + ch + '"; doing nothing');
      }
    };

    function WordTokenizer(options) {
      var _ref, _ref1, _ref2;
      this.startRow = (_ref = options != null ? options.startRow : void 0) != null ? _ref : 0;
      this.startCol = (_ref1 = options != null ? options.startCol : void 0) != null ? _ref1 : 0;
      this.vim = (_ref2 = options != null ? options.vim : void 0) != null ? _ref2 : null;
      if (this.vim == null) {
        LOG.error('No reference to Vim model passed to WordTokenizer');
      }
      LOG.info('Instantiating new WordTokenizer with options:', {
        startRow: this.startRow,
        startCol: this.startCol,
        vim: this.vim
      });
    }

    WordTokenizer.prototype.getSmallWordToken = function(direction, startRow, startCol) {
      var ch, col, finishedParsing, lines, row, state, states, text, type;
      if (this.startRow == null) {
        this.startRow = startRow;
      }
      if (this.startCol == null) {
        this.startCol = startCol;
      }
      LOG.debug(sprintf('Executing getSmallWordToken with start row = %s, start col = %s (%s)', this.startRow, this.startCol, direction));
      lines = this.vim.get('buffer').get('lines');
      row = this.startRow;
      col = this.startCol;
      state = 'START';
      text = "";
      finishedParsing = false;
      states = Helpers.smallWordTokenTypes;
      while (!finishedParsing) {
        ch = lines[row].charAt(col);
        type = getSmallWordTokenType(ch);
        LOG.debug('Inspecting character "' + ch + '" (' + type + ')');
        switch (state) {
          case 'START':
            text += ch;
            state = getSmallWordTokenType(ch);
            break;
          case 'ERROR':
            LOG.error('WordTokenizer is in error state; exiting early');
            finishedParsing = true;
            break;
          case states.ALPHA_NUM:
            if (type === states.ALPHA_NUM) {
              text += ch;
            } else if (type === states.SPECIAL) {
              finishedParsing = true;
            } else if (type === states.EMPTY_LINE) {
              finishedParsing = true;
            } else if (type === states.WHITESPACE) {
              finishedParsing = true;
            } else {
              LOG.error('Unknown character type ' + type + ' in state ' + state(+'; returning early'));
              state = 'ERROR';
            }
            break;
          case states.SPECIAL:
            if (type === states.ALPHA_NUM) {
              finishedParsing = true;
            } else if (type === states.SPECIAL) {
              text += ch;
            } else if (type === states.EMPTY_LINE) {
              finishedParsing = true;
            } else if (type === states.WHITESPACE) {
              finishedParsing = true;
            } else {
              LOG.error('Unknown character type ' + type + ' in state ' + state(+'; returning early'));
              state = 'ERROR';
            }
            break;
          case states.EMPTY_LINE:
            if (type === states.ALPHA_NUM) {
              finishedParsing = true;
            } else if (type === states.SPECIAL) {
              finishedParsing = true;
            } else if (type === states.EMPTY_LINE) {
              finishedParsing = true;
            } else if (type === states.WHITESPACE) {
              state = states.WHITESPACE;
            } else {
              LOG.error('Unknown character type ' + type + ' in state ' + state(+'; returning early'));
              state = 'ERROR';
            }
            break;
          case states.WHITESPACE:
            if (type === states.ALPHA_NUM) {
              text += ch;
              state = states.ALPHA_NUM;
            } else if (type === states.SPECIAL) {
              text += ch;
              state = states.SPECIAL;
            } else if (type === states.EMPTY_LINE) {
              finishedParsing = true;
            } else if (type === states.WHITESPACE) {

            } else {
              LOG.error('Unknown character type ' + type + ' in state ' + state(+'; returning early'));
              state = 'ERROR';
            }
            break;
          default:
            LOG.warn('Unknown state ' + state + '; exiting early');
            finishedParsing = true;
        }
        if (direction === 'forward') {
          if (col < lines[row].length - 1) {
            col += 1;
          } else if (row < lines.length - 1) {
            row += 1;
            col = 0;
          } else {
            finishedParsing = true;
            LOG.warn('Hit EOF; unsure what will happen next');
          }
        } else if (direction === 'backward') {
          if (col > 0) {
            col -= 1;
          } else if (row > 0) {
            row -= 1;
            col = lines[row].length - 1;
          } else {
            finishedParsing = true;
            LOG.warn('Hit SOF; unsure what will happen next');
          }
        } else {
          LOG.error('Unknown direction ' + direction);
        }
      }
      LOG.info('Found token "' + text + '"');
      this.startRow = row;
      return this.startCol = col;
    };

    WordTokenizer.prototype.getBigWordToken = function(startRow, startCol) {
      return new BigWordToken({
        type: 'WORD',
        word: 'blah!@#',
        position: {
          row: 0,
          col: 0
        }
      });
    };

    return WordTokenizer;

  })();

}).call(this);
